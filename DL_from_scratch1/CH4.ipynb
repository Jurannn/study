{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CH4. 신경망 학습"
      ],
      "metadata": {
        "id": "7ZvabdD38RIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 손실 함수"
      ],
      "metadata": {
        "id": "XcUluzap8VQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1 오차제곱합"
      ],
      "metadata": {
        "id": "2lMC-87-8YDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-5QMbSFK8K7J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def sum_squares_error(y, t):\n",
        "  return 0.5 * np.sum((y-t)**2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "#ex1. '2'일 확률이 가장 높다고 추정함(0.6)\n",
        "y1 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "print(sum_squares_error(np.array(y1), np.array(t)))\n",
        "\n",
        "#ex2. '7'일 확률이 가장 높다고 추정함(0.6)\n",
        "y2 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print(sum_squares_error(np.array(y2), np.array(t)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFdzyK16IaQt",
        "outputId": "43af9aa8-1172-4d04-85e6-844b1ceab80d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09750000000000003\n",
            "0.5975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.2 교차 엔트로피 오차"
      ],
      "metadata": {
        "id": "tJbsN_9EJP9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y,t):\n",
        "  delta = 1e-7 #y값이 0일때, log가 -inf가 되는 것을 방지\n",
        "  return -np.sum(t * np.log(y+delta))"
      ],
      "metadata": {
        "id": "QGNXqPvMJLcx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = [0,0,1,0,0,0,0,0,0,0]\n",
        "\n",
        "#ex1. '2'일 확률이 가장 높다고 추정함(0.6)\n",
        "y1 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "print(cross_entropy_error(np.array(y1), np.array(t)))\n",
        "\n",
        "#ex2. '7'일 확률이 가장 높다고 추정함(0.6)\n",
        "y2 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "print(cross_entropy_error(np.array(y2), np.array(t)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGKZR-xYMZP5",
        "outputId": "90492363-6805-48b8-fbd6-0909cf5edad2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.510825457099338\n",
            "2.302584092994546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.3 미니배치 학습"
      ],
      "metadata": {
        "id": "tjocwAkLMiP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWxhnla5Mjzf",
        "outputId": "46b47fc4-9f80-4281-e48c-0874e391b285"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')\n",
        "from dataset.mnist import load_mnist"
      ],
      "metadata": {
        "id": "RLYyOLfqPid2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, t_train), (x_tets, t_test) = \\\n",
        "  load_mnist(normalize = True, one_hot_label = True)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(t_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCdKJvFlPllq",
        "outputId": "6b5e2fe0-9848-4aad-b216-021173dc9bcf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터에서 사이즈가 10인 배치를 추출\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "#무작위로 선택한 값을 추출할 인덱스로 사용\n",
        "\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]"
      ],
      "metadata": {
        "id": "KIb4hN-QP1Gg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4.2.4 배치 데이터를 지원하는 교차 엔트로피 오차 구현하기"
      ],
      "metadata": {
        "id": "dZDg2M6sQeha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, t):\n",
        "  if y.ndim == 1: #데이터가 하나인 경우\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "\n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum()"
      ],
      "metadata": {
        "id": "NseGWyhhQaFG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "iNbDavEST0od"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 수치 미분"
      ],
      "metadata": {
        "id": "7tw3Ge4RT1hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.1 미분"
      ],
      "metadata": {
        "id": "IUji5HAOWlHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#중심 차분(중앙 차분)\n",
        "def numerical_diff(f, x):\n",
        "  h = 1e-4\n",
        "  return(f(x+h)-f(x-h))/ (2*h)"
      ],
      "metadata": {
        "id": "cNaHBg8GT1KX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.2 수치 미분의 예"
      ],
      "metadata": {
        "id": "V939jk3UW7zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def function_1(x):\n",
        "  return 0.01*x**2 + 0.1*x"
      ],
      "metadata": {
        "id": "LgzMiXv-WzRd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(0.0, 20.0, 0.1)\n",
        "y = function_1(x)\n",
        "plt.plot(x,y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GaOnYkrhXCNq",
        "outputId": "7d195fbb-dd99-40ca-b3d2-35c894431add"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_diff(function_1, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-AV50KkXMK-",
        "outputId": "ad59366c-01f8-4305-b556-2b0707305259"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1999999999990898"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_diff(function_1, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTqoXR6HXQHt",
        "outputId": "eae63b94-c9dc-434b-d75f-733986d87eee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2999999999986347"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.3 편미분"
      ],
      "metadata": {
        "id": "yJubAhYKXgPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def function_2(x):\n",
        "  return np.sum(x**2)"
      ],
      "metadata": {
        "id": "QBtG1XzeXSJe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x0=3, x=4일 때, x0에 대한 편미분\n",
        "def function_tmp1(x0):\n",
        "  return x0*x0 + 4.0**2.0\n",
        "\n",
        "numerical_diff(function_tmp1, 3.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4O1sQWFXknv",
        "outputId": "c97e8687-6999-4340-97db-217a629e9893"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.00000000000378"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x0=3, x=4일 때, x1에 대한 편미분\n",
        "def function_tmp2(x1):\n",
        "  return 3.0**2.0 + x1*x1\n",
        "\n",
        "numerical_diff(function_tmp2, 4.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KQ0SIpeYDXe",
        "outputId": "adafd4a2-d34b-4025-a249-86b91c9268e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.999999999999119"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<Br>"
      ],
      "metadata": {
        "id": "LYYPHpYzoZ8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 기울기"
      ],
      "metadata": {
        "id": "XhkZtzJVoc6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기울기(gradient) : 모든 변수의 편미분을 벡터로 정리한 것"
      ],
      "metadata": {
        "id": "8DCfXbi3ofNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def numerical_gradient(f, x):\n",
        "  h = 1e-4\n",
        "  grad = np.zeros_like(x)\n",
        "\n",
        "  for idx in range(x.size):\n",
        "    tmp_val = x[idx]\n",
        "\n",
        "    #f(x+h) 계산\n",
        "    x[idx] = tmp_val + h\n",
        "    fxh1 = f(x)\n",
        "\n",
        "    #f(x-h) 계산\n",
        "    x[idx] = tmp_val - h\n",
        "    fxh2 = f(x)\n",
        "\n",
        "    grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "    x[idx] = tmp_val #값 복원\n",
        "\n",
        "  return grad"
      ],
      "metadata": {
        "id": "WL0krjoyoacI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_gradient(function_2, np.array([3.0, 4.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1X1-uBMpWlw",
        "outputId": "f06cfa86-a05f-46f4-e366-cabd5d18cd65"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_gradient(function_2, np.array([0.0, 2.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl4IziFYpbHg",
        "outputId": "aaaea304-f418-4488-e147-b7f738f1b548"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_gradient(function_2, np.array([3.0, 0.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwZmwMR9phRa",
        "outputId": "eb58afe5-c688-4722-bfb4-9863622e189c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 기울기가 가리키는 쪽으 각 장소에서 출력 값을 가장 크게 줄이는 방향"
      ],
      "metadata": {
        "id": "AqZlaa0cpx6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.1 경사법(경사 하강법)"
      ],
      "metadata": {
        "id": "2BcViZOop2xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#경사 하강법의 구현\n",
        "def gradient_descent(f, init_x, lr = 0.01, step_num = 100):\n",
        "  x = init_x #초깃값\n",
        "\n",
        "  for i in range(step_num): #step_num : 경사 하강법ㅇ에 따른 반복 횟수\n",
        "    grad = numerical_gradient(f,x)\n",
        "    x -= lr*grad #lr = learning rate, 학습률\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "baZapDtKpjyn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q. 경사하강법으로 f(x0, x1) = x0^2 + x1^2 의 최솟값을 구하라."
      ],
      "metadata": {
        "id": "-qBPkuCwrYdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def function_2(x):\n",
        "  return x[0]**2 + x[1]**2\n",
        "\n",
        "init_x = np.array([-3.0, -4.0])\n",
        "gradient_descent(function_2, init_x, lr = 0.1, step_num = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEnhGyKYrVmq",
        "outputId": "4b34e217-065d-4a95-d876-64b173dcce62"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.11110793e-10, -8.14814391e-10])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습률이 너무 큰 경우 ex. lr = 10.0\n",
        "init_x = np.array([-3.0, -4.0])\n",
        "gradient_descent(function_2, init_x, lr = 10.0, step_num = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSVzwWQ0rxGf",
        "outputId": "24f3eca7-a4ec-4225-d141-61868025aaf6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.58983747e+13,  1.29524862e+12])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습률이 너무 작은 경우 ex. lr = 1e-10\n",
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x, lr = 1e-10, step_num = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_wNp7_OsCy3",
        "outputId": "489a25ef-5c92-4836-d5c8-be50b7a250e5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.99999994,  3.99999992])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습률이 큰 경우 큰 값으로 발산\n",
        "- 학습률이 작은 경우 초깃값에서 거의 갱신되지 않음"
      ],
      "metadata": {
        "id": "W38EU8UosVGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4.2 신경망에서의 기울기"
      ],
      "metadata": {
        "id": "uk82KZheshdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서의 기울기는 가중치 매개변수에 대한 손실함수의 기울기를 의미"
      ],
      "metadata": {
        "id": "z0iRLF3ysmvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from common.functions import softmax, cross_entropy_error\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "class simpleNet:\n",
        "  def __init__(self):\n",
        "    self.W = np.random.randn(2,3) #정규분포로 초기화\n",
        "\n",
        "  def predict(self, x):\n",
        "    return np.dot(x, self.W)\n",
        "  \n",
        "  def loss(self, x, t):\n",
        "    z = self.predict(x)\n",
        "    y = softmax(z)\n",
        "    loss = cross_entropy_error(y, t)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "C-E1CTmdsU4F"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = simpleNet()\n",
        "print(net.W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lbX3-VqsR66",
        "outputId": "96ebe417-aca3-4d1c-e99d-84bef8cda61e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.01867394  1.43003125 -1.20774157]\n",
            " [ 1.97640796 -0.59539994  0.70850347]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLTwWYYlxUZv",
        "outputId": "f4c3b2b7-99ef-40be-d401-f528a6d3272a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.38997153  0.32215881 -0.08699182]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP3unKJfxpo_",
        "outputId": "b057afe0-1352-476f-858f-75def1733b65"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.array([0, 0, 1]) #정답 레이블\n",
        "net.loss(x, t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrZG2lAPxr8a",
        "outputId": "2c109063-7f0f-4173-f4f7-e2f655b389d6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.6679623609708774"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기울기 계산\n",
        "def f(W): #W를 인수로 받아 손실 함수를 계산하는 새로운 함수 f를 정의\n",
        "  return net.loss(x, t)\n",
        "\n",
        "dW = numerical_gradient(f, net.W)\n",
        "print(dW)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC2r7kVuxv45",
        "outputId": "aa1abad3-25ee-4a3f-ad75-56862438987a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.49567862  0.06268455 -0.55836317]\n",
            " [ 0.74351792  0.09402683 -0.83754475]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#함수 구현 방법 - lambda 이용\n",
        "f = lambda w: net.loss(x,t)\n",
        "dW = numerical_gradient(f, net.W)"
      ],
      "metadata": {
        "id": "HxojJ5c_yUxA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "zufF_H_5y5Mn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 학습 알고리즘 구현하기"
      ],
      "metadata": {
        "id": "YLtSAouOy6MS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.1 2층 신경망 클래스 구현하기"
      ],
      "metadata": {
        "id": "jOefoKSIzSWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "DtFSjS898QzZ"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from common.functions import *\n",
        "from common.gradient import numerical_gradient\n",
        "\n",
        "class TwoLayerNet:\n",
        "  def __init__(self, input_size, hidden_size, output_size, \n",
        "               weight_init_std = 0.01):\n",
        "  \n",
        "    #가중치 초기화\n",
        "    self.params = {}\n",
        "    self.params['W1'] = weight_init_std*\\\n",
        "                        np.random.randn(input_size, hidden_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['W2'] = weight_init_std*\\\n",
        "                        np.random.randn(hidden_size, output_size)\n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "  def predict(self, x):\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    y = softmax(a2)\n",
        "\n",
        "    return y\n",
        "  \n",
        "  def loss(self, x, t): #x(입력 데이터), t(정답답 레이블)\n",
        "    y = self.predict(x)\n",
        "    y = np.argmax(y, axis = 1)\n",
        "    t = np.argmax(t, axis = 1)\n",
        "\n",
        "    accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "    return accuracy\n",
        "  \n",
        "  def numerical_gradient(self, x, t):\n",
        "    loss_W = lambda W : self.loss(x, t)\n",
        "\n",
        "    grads = {}\n",
        "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "\n",
        "    return grads"
      ],
      "metadata": {
        "id": "BrwOXawiy1Yn"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = TwoLayerNet(input_size = 784, hidden_size = 100, output_size = 10)\n",
        "print(net.params['W1'].shape)\n",
        "print(net.params['b1'].shape)\n",
        "print(net.params['W2'].shape)\n",
        "print(net.params['b2'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZeKD1rTzLCp",
        "outputId": "f4388cef-ff91-45f2-b1b9-2cd1f29d5c11"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(784, 10)\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.2 미니배치 학습 구현하기"
      ],
      "metadata": {
        "id": "tyoSKq4r3TFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = \\\n",
        "  load_mnist(normalize = True, one_hot_label = True)\n",
        "\n",
        "train_loss_list = []\n",
        "\n",
        "#하이퍼파라미터\n",
        "iters_num = 10000 #반반복 횟수\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100 #미니배치 크기\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "  #미니배치 획득\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_mask]\n",
        "  t_batch = t_train[batch_mask]\n",
        "\n",
        "  #기울기 계산\n",
        "  grad = network.numerical_gradient(x_batch, t_batch)\n",
        "  \n",
        "  #매개변수 갱신\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "  #학습 경과 기록\n",
        "  loss = network.loss(x_batch, t_batch)\n",
        "  train_loss_list.append(loss)"
      ],
      "metadata": {
        "id": "YPEiudiX2Gdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5.3 시험 데이터로 평가하기"
      ],
      "metadata": {
        "id": "6qLs1Uh1_Z68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = \\\n",
        "  load_mnist(normalize = True, one_hot_label = True)\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "\n",
        "#1에폭 당 반복 수\n",
        "iter_per_epoch = max(train_size/batch_size, 1)\n",
        "\n",
        "\n",
        "for i in range(iters_num):\n",
        "  #미니배치 획득\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train[batch_mask]\n",
        "  t_batch = t_train[batch_mask]\n",
        "\n",
        "  #기울기 계산\n",
        "  grad = network.numerical_gradient(x_batch, t_batch)\n",
        "  \n",
        "  #매개변수 갱신\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "  #학습 경과 기록\n",
        "  loss = network.loss(x_batch, t_batch)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  #1에폭당 정확도 계산\n",
        "  if i % iter_per_epoch == 0:\n",
        "    train_acc = network.accuracy(x_train, t_train)\n",
        "    test_acc = network.accuracy(x_test, t_test)\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(test_acc)\n",
        "    print(\"train acc, test acc : \" + str(train_acc) + ', ' + str(test_acc))"
      ],
      "metadata": {
        "id": "PJw3ecQe3djH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}